### Metric learning

 1. https://habr.com/ru/companies/ntechlab/articles/586770/
 2. https://habr.com/ru/companies/ntechlab/articles/531842/
 3. https://erikbern.com/2015/10/01/nearest-neighbors-and-vector-models-part-2-how-to-search-in-high-dimensional-spaces.html
 4. https://towardsdatascience.com/comprehensive-guide-to-approximate-nearest-neighbors-algorithms-8b94f057d6b6

Notes:
 1. Датасеты для распознования лиц: MSCeleb (100k celebrities, 10 Million images, 100 per person), LFW (13k images from the web, 1680 persons),  Megaface, our - Vk
 2. Metric learning: для каждого объекта вводиться эмбединг вектор, расстояния между векторами объектов одного - малое, для объектов разных классов - большое
 3. Расстояние  - минковского (евклидова, Манхэтон), махаланобис 
 4. Если обучить чисто кроссэнтропией как задача классификации - плохой результат, объекты плохо разделяются в латентном пространстве. А нам нужно чтобы возникали кластера для каждого отдельного класса
 5. Siamese networks - у нас есть вде копии нейросети, отправляем каждый раз фотографии двух объектов, если они относяться к одному классу - сближаем их вектора эмбедингов, или отдаляем друг от друга в противном случае; Classification similarity loss
 6. Triplet loss: $Loss(a,p,n) = max(0, m+d(a,p)-d(a,n)$ - мы хотим, чтобы расстояние между фотографиями одного человека было как минимум на $\m$ меньше расстояния между фотографией того же человека и какого-то другого.
 7. Если подбирать слишком сложные негативы - обучение может захлебнуться на ранней стадии. Поэтому в качестве негативов нужно использовать более менее приемлимые объекты. Эта проблема нивелируется большим размером датасета
 8. Основной минус данного подхода - плохая сходимость
 9. Center loss - мы дополнительно можем ввести функцию штрафующую за большое расстоянием между эмбедингом объекта и центром класстера для правильного класса, т.е. с каждым разом мы толкаем эмбединг вектор в соответствущий кластер. Final loss = Cross Entropy + λ Center loss
 10. Проблема данного подхода - нам нужно каждый раз пресчитывать вектор центра кластера используя полный датасет, решение проблемы - we train centers as parameters & update
on mini-batch
 11. На выход слоя классификации имеем: $W^{T}X$ (bias берем равынм нулю). Данное произведение является не чем иным, как скалярным произведением вектора лица на каждый из центроидов, так как последний слой это просто матрица из "типичныx" векторов - центроидов для каждого класса. 
 12. Таким образом, если нормы последнего слоя и эмбединга вектора прогоняемого объекта будет равна 1 мы получим что $W^{T}X$ и есть косинусные расстояния между данным объектом и центроидом каждого класса
 13. Итак, у нас есть некие центроиды и текущий вектор лица, а после слоя классификации — косинусы углов между ними. В 2D это будет выглядеть примерно так: ![image](https://github.com/AbdullaevG/comp_vision_course/assets/53749894/0c843f09-4231-4667-b74c-e460c1094e27)
 14. Если теперь мы будем использовать эти выходы в качестве инпутов для софтмакс то данный софтмак слой называется - Normalized Softmax Loss
 15. Границы пространств для различных классов могут быть близки друг к другу, расстояние (угол) между изображениями на границах близких классов может быть меньше, чем расстояние между некоторыми изображениями одного класса.
 16. Идея — добавить между этими пространствами некоторую пустую область (decision margin). Размер этой области — margin гиперпараметр модели: ![image](https://github.com/AbdullaevG/comp_vision_course/assets/53749894/bbcf8d27-b74a-4a51-a895-11fa0c0804ae)

 17. Куда добавить margin для позитивного случая:
     - домножить на угол: вместо $\cos(\theta)$ использовать $\cos(m\theta)$  - Large-Margin Softmax Loss и SphereFace.
     - Отнять margin от косинуса угла: вместо $\cos(\theta)$ используем $\cos(\theta) - m$ -  AM-Softmax и CosFace
     - Прибавить margin непосредственно к углу: вместо $\cos(\theta)$ использовать $\cos(m+\theta)$ - ArcFace, небольшая модификация  AirFace
     - 
